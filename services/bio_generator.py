#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BioGenerator - Service de g√©n√©ration de biographies
"""

import os
import re
import json
import urllib.request
import urllib.error
import requests
import gc
from typing import Dict, List, Optional

GEMINI_MODEL   = "gemini-2.0-flash"
GEMINI_API_URL = ("https://generativelanguage.googleapis.com/v1beta/models"
                  "/{model}:generateContent?key={key}")

SYSTEM_PROMPT_BIO = """Tu es un r√©dacteur expert pour une base de donn√©es de films pour adultes.
Ton objectif est de r√©diger une biographie structur√©e et professionnelle en FRAN√áAIS (Qu√©bec) pour l'artiste, bas√©e sur les faits fournis ET sur tes connaissances personnelles sur cet artiste.

STRUCTURE OBLIGATOIRE (7 sections, dans cet ordre) :

### [Nom] : [Sous-titre accrocheur]

**Introduction** ‚Äî 2-3 phrases : identit√© compl√®te, date et lieu de naissance, ann√©e d√©but de carri√®re, pseudonymes principaux.

**üìÖ Origines et Premiers Pas** ‚Äî 3-4 phrases : origines culturelles, vie avant l'industrie, entr√©e dans l'industrie, ambition.

**üèÜ Carri√®re et Filmographie** ‚Äî 4-5 phrases : studios partenaires, diversit√© des r√¥les, √©volution, apog√©e, constance qualitative. Enrichis avec des faits r√©els si tu les connais.

**üí° Faits Marquants & Personnalit√©** ‚Äî 3-4 phrases : personnalit√©, vie priv√©e, loisirs, anecdotes notables. Utilise les trivia fournis.

**üëó Apparence et Style** ‚Äî 3-4 phrases : description physique compl√®te en prose (cheveux, mensurations, origines, tatouages/piercings), style sc√©nique.

**üèÜ Prix et Distinctions** ‚Äî 3-4 phrases : c√©r√©monies et victoires sp√©cifiques int√©gr√©es en prose, jamais en liste.

**Conclusion rapide** ‚Äî 2 phrases : bilan, h√©ritage, avenir.

R√àGLES ABSOLUES :
- Z√âRO liste √† puces ‚Äî uniquement paragraphes en prose fluide
- Mesures/taille/poids int√©gr√©s naturellement dans la prose d'Apparence
- Prix int√©gr√©s en phrase, JAMAIS sous forme ann√©e-cat√©gorie
- Fran√ßais professionnel et soutenu, avec une touche qu√©b√©coise
- Utiliser ABSOLUTEMENT toutes les donn√©es fournies
- Tu peux enrichir avec tes propres connaissances sur l'artiste (studios r√©els, prix connus, etc.)
- Ne pas mentionner que tu es une IA
- Longueur cible : 2800 √† 3500 caract√®res
"""


class BioGenerator:
    """G√©n√©rateur de biographies avec Gemini (recherche web) et Ollama (local)"""

    def __init__(self, ollama_url: str = "http://localhost:11434/api/generate"):
        self.ollama_url = ollama_url
        # GPU settings for Ollama generation
        self.ollama_num_gpu = int(os.getenv("OLLAMA_NUM_GPU", "999"))
        self.ollama_num_thread = int(os.getenv("OLLAMA_NUM_THREAD", "8"))
        self.gemini_key = self._load_gemini_key()
        self.gemini_search_enabled = True
        self._gemini_disabled = False
        self._gemini_warned_search_disabled = False
        self._gemini_warned_disabled = False
        self._interview_cache: Dict[str, str] = {}
        if self.gemini_key:
            print("[BioGenerator] Cl√© Gemini charg√©e ‚Äî g√©n√©ration Google avec IA activ√©e.")
        else:
            print("[BioGenerator] Pas de cl√© Gemini ‚Äî g√©n√©ration Google en mode template.")
        print(f"[OLLAMA] Options GPU actives: num_gpu={self.ollama_num_gpu}, num_thread={self.ollama_num_thread}")

    def _get_interview_context(self, performer_name: str, metadata: Dict) -> str:
        """Construit un contexte compact depuis les URLs d'interviews.

        Objectif: enrichir la g√©n√©ration de bio avec des infos biographiques fiables
        (Q/R, parcours, anecdotes). Limit√© pour √©viter de ralentir le workflow.
        """
        urls = metadata.get("urls") or []
        if isinstance(urls, str):
            urls = [u.strip() for u in re.split(r"[\s,\n\r]+", urls) if u.strip()]
        if not isinstance(urls, list) or not urls:
            return ""

        try:
            from services.interview_extractor import is_interview_url, extract_interview_text
        except Exception:
            return ""

        interview_urls = [u for u in urls if isinstance(u, str) and is_interview_url(u)]
        if not interview_urls:
            return ""

        # Limites conservatrices
        max_pages = 2
        max_chars = 2500

        chunks: List[str] = []
        used = 0
        for u in interview_urls[:max_pages]:
            u = u.strip()
            if not u:
                continue

            if u in self._interview_cache:
                text = self._interview_cache[u]
            else:
                title, text_raw = extract_interview_text(u)
                text = ""
                if text_raw:
                    header = f"SOURCE INTERVIEW: {u}"
                    if title:
                        header += f"\nTITRE: {title.strip()}"
                    text = (header + "\n" + text_raw.strip()).strip()
                self._interview_cache[u] = text

            if not text:
                continue

            remaining = max_chars - used
            if remaining <= 0:
                break
            if len(text) > remaining:
                text = text[:remaining]
            chunks.append(text)
            used += len(text) + 2

        combined = "\n\n".join(chunks).strip()
        if combined:
            print(f"[BioGenerator] Contexte interviews ajout√© ({len(combined)} chars) ‚Äî {performer_name}")
        return combined

    def _ollama_request(self, model: str, prompt: str, timeout: int = 360) -> Optional[str]:
        """Call Ollama with GPU-preferred options and safe fallback."""
        payload_gpu = {
            "model": model,
            "prompt": prompt,
            "stream": False,
            "keep_alive": "15m",
            "options": {
                "num_gpu": self.ollama_num_gpu,
                "num_thread": self.ollama_num_thread,
            }
        }

        try:
            response = requests.post(self.ollama_url, json=payload_gpu, timeout=timeout)
            if response.status_code == 200:
                data = response.json()
                text = data.get('response', '')
                if text:
                    print(f"[OLLAMA] G√©n√©ration OK (GPU demand√©) ‚Äî model={model}")
                    return text
            else:
                print(f"[OLLAMA] R√©ponse non-200 avec options GPU: {response.status_code}")
        except Exception as e:
            print(f"[OLLAMA] Erreur appel GPU, fallback CPU/auto: {e}")

        # Fallback sans options explicites
        try:
            payload_fallback = {
                "model": model,
                "prompt": prompt,
                "stream": False,
            }
            response = requests.post(self.ollama_url, json=payload_fallback, timeout=timeout)
            if response.status_code == 200:
                data = response.json()
                text = data.get('response', '')
                if text:
                    print(f"[OLLAMA] G√©n√©ration OK (fallback) ‚Äî model={model}")
                    return text
            return None
        except Exception as e:
            print(f"[OLLAMA] Erreur fallback: {e}")
            return None

    def clear_runtime_caches(self, model: str = "dolphin-mistral:7b") -> bool:
        """Clear Python runtime cache and ask Ollama to unload model from RAM/VRAM."""
        ok = True
        try:
            gc.collect()
        except Exception:
            ok = False

        # Ask Ollama to unload model from memory cache
        try:
            unload_payload = {
                "model": model,
                "prompt": "",
                "stream": False,
                "keep_alive": 0,
            }
            resp = requests.post(self.ollama_url, json=unload_payload, timeout=30)
            if resp.status_code == 200:
                print(f"[OLLAMA] Cache mod√®le d√©charg√©: {model}")
            else:
                ok = False
                print(f"[OLLAMA] √âchec clear cache mod√®le ({resp.status_code})")
        except Exception as e:
            ok = False
            print(f"[OLLAMA] Erreur clear cache: {e}")

        return ok

    def _load_gemini_key(self) -> Optional[str]:
        """Cherche .gemini_key √† la racine du projet."""
        root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
        for path in [os.path.join(root, ".gemini_key"), r"F:\Nouveau dossier\.gemini_key"]:
            if os.path.exists(path):
                try:
                    key = open(path, 'r').read().strip()
                    if key:
                        return key
                except Exception:
                    pass
        return None

    def _call_gemini(self, user_prompt: str, use_search: bool = True) -> Optional[str]:
        """Appelle Gemini 2.0 Flash, avec grounding Google Search si use_search=True."""
        if not self.gemini_key or self._gemini_disabled:
            return None

        do_search = bool(use_search and self.gemini_search_enabled)
        url = GEMINI_API_URL.format(model=GEMINI_MODEL, key=self.gemini_key)
        payload: Dict = {
            "system_instruction": {"parts": [{"text": SYSTEM_PROMPT_BIO}]},
            "contents": [{"parts": [{"text": user_prompt}]}],
            "generationConfig": {
                "temperature": 0.75,
                "maxOutputTokens": 1500,
            },
        }
        if do_search:
            # Grounding Google Search : Gemini va chercher sur le web pour enrichir la bio
            payload["tools"] = [{"google_search": {}}]

        try:
            data = json.dumps(payload).encode("utf-8")
            req = urllib.request.Request(
                url, data=data,
                headers={"Content-Type": "application/json"}
            )
            with urllib.request.urlopen(req, timeout=30) as resp:
                result = json.loads(resp.read())
            text = result["candidates"][0]["content"]["parts"][0]["text"]
            return text.strip()
        except urllib.error.HTTPError as e:
            # 401/403 arrivent souvent quand l'API key n'a pas les droits pour le grounding google_search.
            code = getattr(e, "code", None)

            # Si le grounding est activ√© et qu'on re√ßoit 403/401, on retente une fois sans search.
            if code in (401, 403) and do_search:
                self.gemini_search_enabled = False
                if not self._gemini_warned_search_disabled:
                    self._gemini_warned_search_disabled = True
                    print("[GEMINI] 403/401 avec google_search ‚Äî retry sans search et grounding d√©sactiv√© pour la session.")
                return self._call_gemini(user_prompt, use_search=False)

            # Si m√™me sans search on est en 401/403, on d√©sactive Gemini pour √©viter le spam.
            if code in (401, 403):
                self._gemini_disabled = True
                if not self._gemini_warned_disabled:
                    self._gemini_warned_disabled = True
                    print("[GEMINI] 403/401 persistant ‚Äî Gemini d√©sactiv√© pour la session (cl√©/droits √† v√©rifier).")
                return None

            print(f"[GEMINI] Erreur HTTP {code} : {e}")
            return None
        except Exception as e:
            print(f"[GEMINI] Erreur : {e}")
            return None

    def clean_awards_with_gemini(self, raw_awards: str) -> str:
        """
        Utilise Gemini pour nettoyer et formater les awards.
        Fallback sur regex si Gemini √©choue ou prend trop de temps.
        """
        if not raw_awards or not raw_awards.strip():
            return ""
        
        # Si pas de cl√© Gemini, utiliser fallback imm√©diatement
        if not self.gemini_key:
            from utils.normalizer import clean_awards_field
            return clean_awards_field(raw_awards)
        
        prompt = f"""Nettoie et formate cette liste d'awards de performer adulte.

R√àGLES :
1. Une ligne par award, format : "ANN√âE ORGANISATION - Cat√©gorie (Film si mentionn√©) [Winner/Nominee]"
2. Organisations reconnues : AVN Award, XBIZ Award, XRCO Award, NightMoves Award, Spank Bank Award, PornHub Award
3. Supprimer TOUTES les phrases de prose/bio (ex: "she has been", "she was also", "including", etc.)
4. S√©parer les awards coll√©s (ex: "Awards2015 Nominee: Cat1 Nominee: Cat2" ‚Üí 2 lignes distinctes)
5. Nettoyer les caract√®res UTF-8 mal encod√©s (√É‚Äö√¢‚Ç¨, etc.)
6. Si l'ann√©e ou l'organisation manque, tenter de l'inf√©rer du contexte

TEXTE BRUT :
{raw_awards[:3000]}

Retourne UNIQUEMENT la liste nettoy√©e, une ligne par award, sans explication."""

        try:
            cleaned = self._call_gemini(prompt, use_search=False)
            if cleaned and len(cleaned) > 20:  # Validation minimale
                return cleaned
        except Exception as e:
            print(f"[GEMINI] Erreur nettoyage awards : {e}")
        
        # Fallback sur regex
        from utils.normalizer import clean_awards_field
        return clean_awards_field(raw_awards)



    def _summarize_awards(self, awards_raw: str) -> str:
        """Convertit une liste d'awards nettoy√©s en une phrase de prose."""
        if not awards_raw or not awards_raw.strip():
            return ""
        lines = [l.strip() for l in awards_raw.splitlines() if l.strip()]
        ceremonies = set()
        wins = []
        nom_count = 0
        
        for line in lines:
            # Ignorer les lignes vides ou trop courtes
            if len(line) < 5:
                continue
            
            # Pattern pour nouveau format: "2015 AVN Award - Category [Status]"
            m = re.match(r'^(\d{4})\s+([A-Za-z\s]+Award)\s*-\s*(.+?)\s*(?:\[(Winner|Nominee)\])?$', line, re.I)
            if m:
                year, org, category, status = m.groups()
                ceremonies.add(org.strip())
                
                # Nettoyer la cat√©gorie (retirer ≈ìuvre entre parenth√®ses pour le r√©sum√©)
                category = re.sub(r'\s*\([^)]+\)', '', category).strip()
                
                if status and 'winner' in status.lower():
                    wins.append(f"{category} ({year})")
                else:
                    nom_count += 1
            
            # Ancien format pour compatibilit√© : "2015 - Nominee: Category"
            else:
                old_m = re.match(r'^(\d{4})\s*[-‚Äì]\s*(Winner|Nominee)\s*:\s*(.+)$', line, re.I)
                if old_m:
                    year, status, category = old_m.groups()
                    category = re.sub(r'\s*\([^)]+\)', '', category).strip()
                    if 'winner' in status.lower():
                        wins.append(f"{category} ({year})")
                    else:
                        nom_count += 1
        
        if not ceremonies and not wins and nom_count == 0:
            return ""
        
        cer_str = " et ".join(sorted(ceremonies)) if ceremonies else "plusieurs c√©r√©monies de l'industrie"
        parts = []
        
        if wins:
            win_str = ", ".join(wins[:3])
            if len(wins) > 3:
                win_str += f" et {len(wins)-3} autre(s) troph√©e(s)"
            parts.append(f"remportant notamment {win_str}")
        
        if nom_count:
            parts.append(f"cumulant plus de {nom_count} nomination(s)")
        
        detail = ", ".join(parts)
        if detail:
            return f"Son talent a √©t√© salu√© aux {cer_str}, {detail}."
        return f"Son talent a √©t√© reconnu par de multiples distinctions aux {cer_str}."


    def _prose_appearance(self, measurements: str, height: str, weight: str,
                          hair_color: str, ethnicity: str,
                          tattoos: str, piercings: str) -> str:
        """R√©dige la section apparence sous forme de prose."""
        parts = []
        if hair_color and hair_color not in ('[couleur]', 'Non disponible'):
            parts.append(f"Sa chevelure {hair_color.lower()} encadre un visage expressif")
        if measurements and measurements not in ('[mesures]', 'Non disponible'):
            parts.append(f"sa silhouette est mise en valeur par des mensurations de {measurements}")
        if height and height not in ('[taille]', 'Non disponible'):
            h = str(height).replace('cm', '').strip()
            parts.append(f"une stature de {h} cm")
        if weight and weight not in ('[poids]', 'Non disponible'):
            w = str(weight).replace('kg', '').strip()
            parts.append(f"un poids de {w} kg")
        prose = ""
        if parts:
            prose = ". ".join(p.capitalize() for p in parts) + "."

        body_art = []
        tat = str(tattoos).strip()
        if tat and tat.lower() not in ('none', 'information non disponible', '[mesures]', ''):
            # Condenser une liste multi-lignes en une courte mention
            tat_lines = [l.strip() for l in tat.splitlines() if l.strip()]
            if len(tat_lines) > 2:
                body_art.append(f"plusieurs tatouages ornent son corps")
            elif len(tat_lines) > 0:
                body_art.append(f"elle arbore {tat_lines[0].lower()}")
        pier = str(piercings).strip()
        if pier and pier.lower() not in ('none', 'information non disponible', ''):
            body_art.append(f"des piercings {pier.lower()}")
        if body_art:
            prose += " " + " et ".join(body_art).capitalize() + "."
        return prose.strip()

    def _prose_trivia(self, trivia: str) -> str:
        """Condense une liste de faits trivia en prose fluide."""
        if not trivia or not trivia.strip():
            return ""
        lines = [l.strip().rstrip('.') for l in trivia.splitlines() if l.strip()]
        if len(lines) == 1:
            return lines[0] + "."
        selected = lines[:3]
        if len(selected) == 1:
            return selected[0] + "."
        return ". ".join(selected) + "."

    def _prose_bio_raw(self, bio_raw: str, performer_name: str) -> str:
        """Extrait 2-3 phrases pertinentes du bio_raw scrapp√© pour enrichir la section carri√®re."""
        if not bio_raw or not bio_raw.strip():
            return ""
        # Garder les phrases qui contiennent des infos de carri√®re (studios, ann√©es, prix...)
        sentences = re.split(r'(?<=[.!?])\s+', bio_raw.strip())
        keywords = re.compile(
            r'\b(studio|brazzers|evil angel|digital|mofos|naughty|reality|\d{4}|'
            r'award|avn|xbiz|carri√®re|career|film|sc√®ne|scene|travaill|work|'
            r'collaborate|nomm|nomin|won|remport|gagn)\b', re.I)
        relevant = [s.strip() for s in sentences if keywords.search(s) and len(s) > 40]
        if not relevant:
            # fallback : prendre les 2 premi√®res phrases non vides
            relevant = [s.strip() for s in sentences if len(s.strip()) > 40][:2]
        return ' '.join(relevant[:3])
        if len(lines) == 1:
            return lines[0] + "."
        # Garder les 3 premiers faits max, les joindre en prose
        selected = lines[:3]
        if len(selected) == 1:
            return selected[0] + "."
        return ". ".join(selected) + "."

    def generate_google_bio(self, performer_name: str, metadata: Dict) -> str:
        """G√©n√®re une bio via Gemini 2.0 Flash (avec recherche web) si cl√© dispo, sinon template local."""
        # Donn√©es brutes
        birthdate    = metadata.get('birthdate')    or ''
        birthplace   = metadata.get('birthplace')   or metadata.get('country') or ''
        career_start = metadata.get('career_start') or ''
        if not career_start and metadata.get('career_length'):
            career_start = str(metadata['career_length']).split('-')[0].strip()
        aliases      = metadata.get('aliases') or []
        ethnicity    = metadata.get('ethnicity')    or ''
        height       = metadata.get('height')       or ''
        weight       = metadata.get('weight')       or ''
        measurements = metadata.get('measurements') or ''
        hair_color   = metadata.get('hair_color')   or ''
        tattoos      = metadata.get('tattoos')      or ''
        piercings    = metadata.get('piercings')    or ''
        trivia       = metadata.get('trivia')       or ''
        awards_raw   = metadata.get('awards') or metadata.get('awards_summary') or ''
        bio_raw      = metadata.get('bio_raw') or metadata.get('details', '')
        stash_bio    = metadata.get('stash_bio', '')  # Bio d√©j√† pr√©sente dans Stash

        interviews_ctx = metadata.get('interviews') or ''
        if not interviews_ctx:
            interviews_ctx = self._get_interview_context(performer_name, metadata)
            if interviews_ctx:
                metadata['interviews'] = interviews_ctx
        if isinstance(aliases, str):
            aliases = [a.strip() for a in re.split(r'[,\n]', aliases) if a.strip()]
        alias_str = ', '.join(aliases) if aliases else performer_name

        # Essai Gemini (avec Google Search grounding)
        if self.gemini_key:
            lines = [
                f"R√©dige une biographie compl√®te en fran√ßais (Qu√©bec) pour : {performer_name}",
                "",
                "DONN√âES FACTUELLES DISPONIBLES :",
            ]
            if birthdate:    lines.append(f"- Date de naissance : {birthdate}")
            if birthplace:   lines.append(f"- Lieu de naissance : {birthplace}")
            if career_start: lines.append(f"- D√©but de carri√®re : {career_start}")
            cl = metadata.get('career_length')
            if cl:           lines.append(f"- Ann√©es d'activit√© : {cl}")
            if alias_str != performer_name: lines.append(f"- Pseudonymes : {alias_str}")
            if ethnicity:    lines.append(f"- Ethnicit√© : {ethnicity}")
            if hair_color:   lines.append(f"- Cheveux : {hair_color}")
            if measurements: lines.append(f"- Mensurations : {measurements}")
            if height:       lines.append(f"- Taille : {height} cm")
            if weight:       lines.append(f"- Poids : {weight} kg")
            if tattoos:      lines.append(f"- Tatouages : {tattoos}")
            if piercings:    lines.append(f"- Piercings : {piercings}")
            if trivia:       lines.append(f"\nTrivia :\n{trivia[:800]}")
            if awards_raw:   lines.append(f"\nAwards :\n{awards_raw[:1200]}")
            if bio_raw:      lines.append(f"\nBio scrap√©e :\n{bio_raw[:1000]}")
            if interviews_ctx:
                lines.append(f"\nInterviews (extraits) :\n{interviews_ctx[:2500]}")
            if stash_bio and stash_bio != bio_raw:
                lines.append(f"\nBio actuelle dans Stash (√† am√©liorer/enrichir) :\n{stash_bio[:1200]}")
            lines += [
                "",
                "Tu peux enrichir avec tes connaissances r√©elles (studios, prix v√©rifiables, faits publics).",
                "Respecte la structure en 7 sections d√©finie dans le syst√®me.",
            ]
            print(f"[GEMINI] G√©n√©ration bio pour {performer_name} (avec recherche web)...")
            result = self._call_gemini("\n".join(lines), use_search=True)
            if result:
                print(f"[GEMINI] Bio g√©n√©r√©e ({len(result)} caract√®res)")
                return result
            print("[GEMINI] √âchec ‚Äî repli sur template local.")

        # Repli template local
        print(f"[BIO] G√©n√©ration template local pour {performer_name}")
        awards_prose     = self._summarize_awards(awards_raw)
        trivia_prose     = self._prose_trivia(trivia)
        appearance_prose = self._prose_appearance(
            measurements, height, weight, hair_color, ethnicity, tattoos, piercings)
        career_enrich    = self._prose_bio_raw(bio_raw or stash_bio, performer_name)
        bd  = birthdate    or '[date de naissance]'
        bp  = birthplace   or '[lieu]'
        cs  = career_start or '[ann√©e de d√©but]'
        eth = ethnicity    or '[origine]'

        intro = (
            f"N√©e le {bd} √† {bp}, {performer_name} est une personnalit√© respect√©e du monde du "
            f"divertissement adulte. D√®s son entr√©e remarqu√©e en {cs}, elle a su s'imposer par "
            f"son charisme et son √©nergie. Connue sous les noms de {alias_str}, elle a navigu√© "
            f"avec succ√®s dans une industrie comp√©titive."
        )
        origines = (
            f"Issue d'une culture {eth}, {performer_name} a pass√© ses premi√®res ann√©es dans la "
            f"r√©gion de {bp}. Son engagement d√®s {cs} t√©moigne d'une volont√© farouche de r√©ussir."
        )
        carriere = (
            "Sa carri√®re est jalonn√©e de succ√®s et de collaborations avec les leaders de l'industrie."
            + (" " + career_enrich if career_enrich else "")
        )
        faits = (
            f"En dehors des plateaux, {performer_name} cultive un univers personnel riche."
            + (" " + trivia_prose if trivia_prose else "")
        )
        apparence = (
            f"Sa beaut√© distinctive, reflet de ses origines {eth}, est l'un de ses traits les plus remarquables. "
            + appearance_prose
        )
        prix = awards_prose or "Ses efforts ont √©t√© couronn√©s par de nombreuses nominations et r√©compenses."
        conclusion = (
            f"En r√©sum√©, {performer_name} est une v√©ritable ic√¥ne de son temps. "
            "Son influence perdurera, laissant une trace ind√©l√©bile dans l'histoire du divertissement moderne."
        )

        tmpl = "\n\n".join([
            f"### {performer_name} : Une Carri√®re d'Excellence et un Parcours Inspirant",
            f"**Introduction**\n{intro}",
            f"**üìÖ Origines et Premiers Pas**\n{origines}",
            f"**üèÜ Carri√®re et Filmographie**\n{carriere}",
            f"**üí° Faits Marquants & Personnalit√©**\n{faits}",
            f"**üëó Apparence et Style**\n{apparence}",
            f"**üèÜ Prix et Distinctions**\n{prix}",
            f"**Conclusion**\n{conclusion}",
        ])
        if len(tmpl) > 3500:
            tmpl = tmpl[:3497] + "..."
        return tmpl

    def generate_ollama_bio(self, performer_name: str, metadata: Dict, custom_prompt: str = "", model: str = "dolphin-mistral:7b") -> Optional[str]:
        """G√©n√®re une bio avec Ollama en int√©grant des directives personnalis√©es"""
        try:
            # Variables pour les f-strings des prompts
            ethnicity   = metadata.get('ethnicity', 'Non disponible')
            hair_color  = metadata.get('hair_color', 'Non disponible')
            measurements= metadata.get('measurements', 'Non disponible')
            height      = metadata.get('height', 'Non disponible')
            weight      = metadata.get('weight', 'Non disponible')
            career_start= metadata.get('career_start', 'Non disponible')

            # Construction des infos de base
            aliases_str = (', '.join(metadata.get('aliases', []))
                           if isinstance(metadata.get('aliases'), list)
                           else metadata.get('aliases', ''))
            info_str = f"""
            - Nom : {performer_name}
            - Aliases / Pseudonymes : {aliases_str}
            - Date de naissance : {metadata.get('birthdate', 'Non disponible')}
            - Lieu de naissance : {metadata.get('birthplace', 'Non disponible')}
            - Ethnicit√© : {ethnicity}
            - D√©but de carri√®re : {career_start}
            - Carri√®re (ann√©es) : {metadata.get('career_length', 'Non disponible')}
            - Mensurations : {measurements}
            - Taille : {height} cm
            - Poids : {weight} kg
            - Couleur de cheveux : {hair_color}
            - Tatouages : {metadata.get('tattoos', 'Non disponible')}
            - Piercings : {metadata.get('piercings', 'Non disponible')}
            """
            
            # Ajout de contexte riche si pr√©sent
            extra_context = ""
            if metadata.get('trivia'):
                extra_context += f"\nFaits marquants (Trivia) :\n{metadata['trivia']}"
            bio_source = metadata.get('bio_raw') or metadata.get('details', '')
            if bio_source:
                extra_context += f"\nBio source scrapp√©e :\n{bio_source}"
            if metadata.get('awards'):
                extra_context += f"\nR√©compenses (brut) :\n{metadata['awards']}"

            interviews_ctx = metadata.get('interviews') or ''
            if not interviews_ctx:
                interviews_ctx = self._get_interview_context(performer_name, metadata)
                if interviews_ctx:
                    metadata['interviews'] = interviews_ctx
            if interviews_ctx:
                extra_context += f"\n\nInterviews (extraits) :\n{interviews_ctx}"

            if custom_prompt:
                prompt = f"""Tu es un r√©dacteur expert en biographies pour l'industrie du divertissement adulte.

OBJECTIF : R√©diger une biographie de 2800 √† 3200 caract√®res pour {performer_name}.
Directives personnalis√©es : {custom_prompt}

STRUCTURE OBLIGATOIRE (7 sections, dans cet ordre) :

### {performer_name} : [sous-titre accrocheur bas√© sur les donn√©es]

**Introduction** ‚Äî 2-3 phrases : identit√© compl√®te, date et lieu de naissance, ann√©e d√©but de carri√®re, pseudonymes principaux.

**üìÖ Origines et Premiers Pas** ‚Äî 3-4 phrases : origines culturelles ({ethnicity}), vie priv√©e discrois, √¢ge/contexte au d√©but de carri√®re ({career_start}), ambition.

**üèÜ Carri√®re et Filmographie** ‚Äî 4-5 phrases : studios partenaires, diversit√© des r√¥les, √©volution, apog√©e, constance qualitative.

**üí° Faits Marquants & Personnalit√©** ‚Äî 3-4 phrases : personnalit√©, approche professionnelle, myst√®re/discroistion sur la vie priv√©e, anecdotes des trivia si piscine.

**üëó Apparence et Style** ‚Äî 3-4 phrases : description physique compl√®te en prose (cheveux {hair_color}, origines {ethnicity}, {measurements}, {height}cm, {weight}kg, tatouages, piercings), style sc√©nique.

**üèÜ Prix et Distinctions** ‚Äî 3-4 phrases : c√©r√©monies et victoires sp√©cifiques int√©gr√©es en prose, jamais en liste.

**Conclusion rapide** ‚Äî 2 phrases : bilan, h√©ritage, avenir.

R√àGLES ABSOLUES :
- Z√âRO liste √† puces ‚Äî uniquement paragraphes en prose fluide
- Mesures/taille/poids int√©gr√©s naturellement dans la prose d'Apparence
- Prix int√©gr√©s en phrase, JAMAIS sous forme ann√©e-cat√©gorie
- Fran√ßais professionnel et soutenu, avec une touche qu√©b√©coise si pertinent
- Utiliser ABSOLUMENT toutes les donn√©es fournies ci-dessous
- Ne pas mentionner que tu es une IA

DONN√âES FACTUELLES :
{info_str}
{extra_context}

R√©ponds UNIQUEMENT avec le texte de la biographie, sans pr√©ambule ni commentaire."""
            else:
                prompt = f"""Tu es un r√©dacteur expert en biographies pour l'industrie du divertissement adulte.

OBJECTIF : R√©diger une biographie compl√®te de 2800 √† 3200 caract√®res pour {performer_name}.

MOD√àLE DE STRUCTURE √† suivre (7 sections) :

### {performer_name} : [sous-titre accrocheur]

**Introduction** ‚Äî N√©e le [date] √† [lieu], [nom] a marqu√© l'industrie d√®s [ann√©e]. Reconnue pour [traits], elle a rapidement acquis une notori√©t√© significative. Ses alias [liste] ont contribu√© √† forger une image polyvalente.

**üìÖ Origines et Premiers Pas** ‚Äî Origines [ethnie], vie priv√©e discroistion, entr√©e dans l'industrie en [ann√©e] √† [age] ans.

**üèÜ Carri√®re et Filmographie** ‚Äî Studios, collaborations, diversit√© des r√¥les, apog√©e, longuit√©vit√©.

**üí° Faits Marquants & Personnalit√©** ‚Äî Personnalit√© authentique, vie priv√©e, loisirs si connus, anecdotes.

**üëó Apparence et Style** ‚Äî Description physique int√©gr√©e en prose (cheveux, mensurations, style).

**üèÜ Prix et Distinctions** ‚Äî Nominations/victoires cit√©es en phrases, jamais en liste.

**Conclusion rapide** ‚Äî Bilan et h√©ritage.

R√àGLES ABSOLUES :
- Z√âRO liste √† puces ‚Äî prose fluide uniquement
- Tous les chiffres (mesures, ann√©es, taille) int√©gr√©s naturellement dans les phrases
- Fran√ßais professionnel, touche qu√©b√©coise bienveille
- Utiliser TOUTES les donn√©es fournies ci-dessous
- Ne pas mentionner l'IA

DONN√âES FACTUELLES COMPL√àTES :
{info_str}
{extra_context}

R√©ponds UNIQUEMENT avec le texte de la biographie, sans pr√©ambule."""
            
            return self._ollama_request(model=model, prompt=prompt, timeout=360)
        except requests.exceptions.ReadTimeout:
            print("[OLLAMA] Timeout d√©pass√© (360s) ‚Äî essayez un mod√®le plus l√©ger.")
            return None
        except Exception as e:
            print(f"Erreur Ollama (generation): {e}")
            return None

    def refine_bio(self, current_bio: str, custom_prompt: str, model: str = "dolphin-mistral:7b") -> Optional[str]:
        """Raffine ou fusionne une bio existante selon des directives IA"""
        try:
            prompt = f"""Tu es un √©diteur expert en biographies pour l'industrie du divertissement adulte.
Modifie le texte suivant en appliquant STRICTEMENT ces directives : {custom_prompt}

R√àGLES :
- CONSERVER la structure 7 sections
- Z√âRO liste √† puces, prose fluide uniquement
- Fran√ßais professionnel
- Ne pas mentionner l'IA

Texte actuel :
---
{current_bio}
---

Renvoie UNIQUEMENT la biographie modifi√©e, sans commentaires."""
            
            return self._ollama_request(model=model, prompt=prompt, timeout=360)
        except requests.exceptions.ReadTimeout:
            print("[OLLAMA] Timeout d√©pass√© (360s) lors du raffinement.")
            return None
        except Exception as e:
            print(f"Erreur Ollama (refinement): {e}")
            return None

    def translate_qc(self, text: str, field_name: str = "", model: str = "dolphin-mistral:7b") -> str:
        """Traduit un texte sp√©cifique en Fran√ßais/QC avec Ollama."""
        if not text or text.lower() == 'none' or len(text.strip()) < 2:
            return text
            
        try:
            prompt = f"""Traduis le texte suivant (champ '{field_name}') en Fran√ßais (style Qu√©b√©cois/QC) de mani√®re naturelle. 
            Si c'est d√©j√† en fran√ßais, am√©liore le style.
            Texte √† traduire : {text}
            Renvoie UNIQUEMENT la traduction, sans commentaires."""
            
            result = self._ollama_request(model=model, prompt=prompt, timeout=60)
            if result:
                result = result.strip()
                return result if result else text
        except Exception as e:
            print(f"[OLLAMA] Erreur traduction {field_name}: {e}")
        return text

    def translate_google(self, text: str, target_lang: str = "fr") -> str:
        """Traduit un texte via l'API Google Translate gratuite (gtx)."""
        if not text or text.lower() == 'none' or len(text.strip()) < 2:
            return text
            
        try:
            url = f"https://translate.googleapis.com/translate_a/single?client=gtx&sl=auto&tl={target_lang}&dt=t&q={text}"
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                data = response.json()
                # La structure est [[["trad", "orig", ...], ...]]
                translated = "".join([part[0] for part in data[0] if part[0]])
                return translated
        except Exception as e:
            print(f"[GOOGLE] Erreur traduction : {e}")
        return text

    def translate_hybrid(self, text: str, field_name: str = "") -> str:
        """Tente Google Translate, bascule sur Ollama si √©chec ou contenu vide."""
        def _is_advice_noise(src: str, candidate: str, fld: str) -> bool:
            if not candidate:
                return True
            low = candidate.lower()
            markers = [
                "cette phrase est d√©j√† en fran√ßais", "cette phrase est deja en francais",
                "pour am√©liorer le style", "pour ameliorer le style",
                "je vous recommande", "par exemple", "il est pr√©f√©rable", "il est preferable",
                "si le style qu√©b√©cois", "si le style quebecois",
                "1.", "2.", "3."
            ]
            if any(m in low for m in markers):
                return True

            # Si sortie beaucoup plus longue que l'entr√©e sur body-art, c'est souvent du commentaire
            fld_low = (fld or "").lower()
            if fld_low in ("tatouages", "tattoos", "piercings") and len(candidate) > max(120, int(len(src) * 2.2)):
                return True

            return False

        # On tente Google d'abord (recommandation utilisateur pour contenu peu explicite)
        res = self.translate_google(text)
        
        # Si Google √©choue ou si le r√©sultat est suspect (trop court par rapport √† l'original)
        # ou si on veut forcer le style QC via Ollama
        if not res or res == text or len(res) < len(text) * 0.3:
            res = self.translate_qc(text, field_name)

        # Garde-fou contre les r√©ponses "conseils" au lieu d'une traduction
        if _is_advice_noise(text, res, field_name):
            return text

        return res
